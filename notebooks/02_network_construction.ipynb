{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "087ceba0",
   "metadata": {},
   "source": [
    "# Network Construction and Visualization - GTA Real Estate Hotspots\n",
    "\n",
    "**Author:** Yadon Kassahun (Network Architect)  \n",
    "**Date:** 2024-11-06  \n",
    "**Purpose:** Visualize and analyze the constructed spatial networks\n",
    "\n",
    "## Objectives\n",
    "1. Load the constructed spatial network\n",
    "2. Visualize network structure\n",
    "3. Analyze network properties\n",
    "4. Compare different edge creation methods\n",
    "5. Explore spatial lag features\n",
    "\n",
    "## Prerequisites\n",
    "Run this first: `python src/network_builder.py --test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dc82ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Network analysis\n",
    "import networkx as nx\n",
    "\n",
    "# Geospatial\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from folium import plugins\n",
    "\n",
    "# Add src to path\n",
    "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "sys.path.append(str(PROJECT_ROOT / 'src'))\n",
    "\n",
    "# Import our modules\n",
    "from network_builder import SpatialNetworkBuilder\n",
    "\n",
    "# Set paths\n",
    "DATA_PROCESSED = PROJECT_ROOT / 'data' / 'processed'\n",
    "RESULTS = PROJECT_ROOT / 'results'\n",
    "\n",
    "# Plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\" Imports successful\")\n",
    "print(f\" Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6958c50d",
   "metadata": {},
   "source": [
    "## 1. Load the Spatial Network\n",
    "\n",
    "Let's load the network we built and examine its basic properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb9852a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find available network files\n",
    "network_dir = DATA_PROCESSED / 'networks'\n",
    "\n",
    "if not network_dir.exists():\n",
    "    print(\" No networks found. Run network builder first:\")\n",
    "    print(\"   python src/network_builder.py --test\")\n",
    "else:\n",
    "    # List available networks\n",
    "    network_files = list(network_dir.glob('*.gpickle'))\n",
    "    \n",
    "    if not network_files:\n",
    "        print(\" No network files found in\", network_dir)\n",
    "    else:\n",
    "        print(f\" Found {len(network_files)} network file(s):\")\n",
    "        for f in network_files:\n",
    "            print(f\"   - {f.name}\")\n",
    "        \n",
    "        # Load the most recent network\n",
    "        latest_network = max(network_files, key=lambda p: p.stat().st_mtime)\n",
    "        print(f\"\\n Loading: {latest_network.name}\")\n",
    "        \n",
    "        # Load using NetworkX\n",
    "        G = nx.read_gpickle(latest_network)\n",
    "        \n",
    "        print(f\"\\n✓ Network loaded successfully!\")\n",
    "        print(f\"   Nodes: {G.number_of_nodes():,}\")\n",
    "        print(f\"   Edges: {G.number_of_edges():,}\")\n",
    "        print(f\"   Graph type: {type(G).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb109a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'G' in locals() and G.number_of_nodes() > 0:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"NETWORK SUMMARY STATISTICS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Basic stats\n",
    "    print(f\"\\n1. Basic Properties:\")\n",
    "    print(f\"   Nodes:              {G.number_of_nodes():,}\")\n",
    "    print(f\"   Edges:              {G.number_of_edges():,}\")\n",
    "    print(f\"   Density:            {nx.density(G):.4f}\")\n",
    "    \n",
    "    # Degree statistics\n",
    "    degrees = dict(G.degree())\n",
    "    degree_values = list(degrees.values())\n",
    "    \n",
    "    print(f\"\\n2. Degree Statistics:\")\n",
    "    print(f\"   Average degree:     {np.mean(degree_values):.2f}\")\n",
    "    print(f\"   Max degree:         {np.max(degree_values)}\")\n",
    "    print(f\"   Min degree:         {np.min(degree_values)}\")\n",
    "    print(f\"   Median degree:      {np.median(degree_values):.0f}\")\n",
    "    \n",
    "    # Connectivity\n",
    "    print(f\"\\n3. Connectivity:\")\n",
    "    print(f\"   Is connected:       {nx.is_connected(G)}\")\n",
    "    print(f\"   Num components:     {nx.number_connected_components(G)}\")\n",
    "    \n",
    "    if nx.is_connected(G):\n",
    "        print(f\"   Diameter:           {nx.diameter(G)}\")\n",
    "        print(f\"   Avg path length:    {nx.average_shortest_path_length(G):.2f}\")\n",
    "    else:\n",
    "        # Stats for largest component\n",
    "        largest_cc = max(nx.connected_components(G), key=len)\n",
    "        G_largest = G.subgraph(largest_cc).copy()\n",
    "        print(f\"   Largest component:  {len(largest_cc)} nodes\")\n",
    "        print(f\"   Diameter (largest): {nx.diameter(G_largest)}\")\n",
    "    \n",
    "    # Clustering\n",
    "    print(f\"\\n4. Clustering:\")\n",
    "    avg_clustering = nx.average_clustering(G)\n",
    "    print(f\"   Avg clustering:     {avg_clustering:.4f}\")\n",
    "    \n",
    "    # Edge weights (if available)\n",
    "    if G.number_of_edges() > 0:\n",
    "        edge_weights = [G[u][v].get('distance_km', 0) for u, v in G.edges()]\n",
    "        edge_weights = [w for w in edge_weights if w > 0]\n",
    "        \n",
    "        if edge_weights:\n",
    "            print(f\"\\n5. Edge Distances:\")\n",
    "            print(f\"   Average distance:   {np.mean(edge_weights):.2f} km\")\n",
    "            print(f\"   Max distance:       {np.max(edge_weights):.2f} km\")\n",
    "            print(f\"   Min distance:       {np.min(edge_weights):.2f} km\")\n",
    "else:\n",
    "    print(\"⚠ Network not loaded or empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c223719",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'G' in locals() and G.number_of_nodes() > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot 1: Degree distribution histogram\n",
    "    degrees = dict(G.degree())\n",
    "    degree_values = list(degrees.values())\n",
    "    \n",
    "    axes[0].hist(degree_values, bins=20, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "    axes[0].set_title('Degree Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Degree (Number of Connections)', fontsize=12)\n",
    "    axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "    axes[0].axvline(np.mean(degree_values), color='red', linestyle='--', \n",
    "                    linewidth=2, label=f'Mean: {np.mean(degree_values):.1f}')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Plot 2: Edge distance distribution (if available)\n",
    "    edge_weights = [G[u][v].get('distance_km', 0) for u, v in G.edges()]\n",
    "    edge_weights = [w for w in edge_weights if w > 0]\n",
    "    \n",
    "    if edge_weights:\n",
    "        axes[1].hist(edge_weights, bins=30, edgecolor='black', alpha=0.7, color='coral')\n",
    "        axes[1].set_title('Edge Distance Distribution', fontsize=14, fontweight='bold')\n",
    "        axes[1].set_xlabel('Distance (km)', fontsize=12)\n",
    "        axes[1].set_ylabel('Frequency', fontsize=12)\n",
    "        axes[1].axvline(np.mean(edge_weights), color='red', linestyle='--', \n",
    "                       linewidth=2, label=f'Mean: {np.mean(edge_weights):.2f} km')\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULTS / 'figures' / 'network_distributions.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\" Figure saved to: {RESULTS / 'figures' / 'network_distributions.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10915b5b",
   "metadata": {},
   "source": [
    "## 2. Network Visualization\n",
    "\n",
    "Let's visualize the network structure both as a graph and on a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3ad3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'G' in locals() and G.number_of_nodes() > 0:\n",
    "    print(\"Creating network graph visualization...\")\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "    \n",
    "    # Get positions based on geographic coordinates\n",
    "    pos = {}\n",
    "    for node in G.nodes():\n",
    "        if 'lat' in G.nodes[node] and 'lon' in G.nodes[node]:\n",
    "            lat = G.nodes[node]['lat']\n",
    "            lon = G.nodes[node]['lon']\n",
    "            pos[node] = (lon, lat)  # Note: NetworkX uses (x, y) = (lon, lat)\n",
    "    \n",
    "    if len(pos) == 0:\n",
    "        print(\"⚠ No geographic coordinates found in nodes. Using spring layout.\")\n",
    "        pos = nx.spring_layout(G, k=0.5, iterations=50)\n",
    "    \n",
    "    # Plot 1: Network with geographic layout\n",
    "    node_colors = list(degrees.values())\n",
    "    \n",
    "    nx.draw_networkx_nodes(\n",
    "        G, pos, \n",
    "        node_color=node_colors,\n",
    "        node_size=100,\n",
    "        cmap='YlOrRd',\n",
    "        alpha=0.8,\n",
    "        ax=axes[0]\n",
    "    )\n",
    "    \n",
    "    nx.draw_networkx_edges(\n",
    "        G, pos,\n",
    "        alpha=0.3,\n",
    "        width=0.5,\n",
    "        edge_color='gray',\n",
    "        ax=axes[0]\n",
    "    )\n",
    "    \n",
    "    axes[0].set_title('Spatial Network - Geographic Layout', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Longitude', fontsize=12)\n",
    "    axes[0].set_ylabel('Latitude', fontsize=12)\n",
    "    axes[0].axis('on')\n",
    "    \n",
    "    # Add colorbar\n",
    "    sm = plt.cm.ScalarMappable(\n",
    "        cmap='YlOrRd',\n",
    "        norm=plt.Normalize(vmin=min(node_colors), vmax=max(node_colors))\n",
    "    )\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, ax=axes[0])\n",
    "    cbar.set_label('Node Degree', fontsize=10)\n",
    "    \n",
    "    # Plot 2: Force-directed layout (better for seeing structure)\n",
    "    pos_spring = nx.spring_layout(G, k=0.3, iterations=50, seed=42)\n",
    "    \n",
    "    nx.draw_networkx_nodes(\n",
    "        G, pos_spring,\n",
    "        node_color=node_colors,\n",
    "        node_size=100,\n",
    "        cmap='YlOrRd',\n",
    "        alpha=0.8,\n",
    "        ax=axes[1]\n",
    "    )\n",
    "    \n",
    "    nx.draw_networkx_edges(\n",
    "        G, pos_spring,\n",
    "        alpha=0.3,\n",
    "        width=0.5,\n",
    "        edge_color='gray',\n",
    "        ax=axes[1]\n",
    "    )\n",
    "    \n",
    "    axes[1].set_title('Network Structure - Spring Layout', fontsize=14, fontweight='bold')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULTS / 'figures' / 'network_visualization.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"✓ Figure saved to: {RESULTS / 'figures' / 'network_visualization.png'}\")\n",
    "    print(\"\\nVisualization Notes:\")\n",
    "    print(\"  - Node color intensity = degree (connectivity)\")\n",
    "    print(\"  - Left: True geographic positions\")\n",
    "    print(\"  - Right: Force-directed layout (shows community structure)\")\n",
    "else:\n",
    "    print(\"⚠ Network not available for visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bb3655",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'G' in locals() and G.number_of_nodes() > 0:\n",
    "    print(\"Creating interactive network map...\")\n",
    "    \n",
    "    # Check if nodes have coordinates\n",
    "    nodes_with_coords = [node for node in G.nodes() \n",
    "                        if 'lat' in G.nodes[node] and 'lon' in G.nodes[node]]\n",
    "    \n",
    "    if len(nodes_with_coords) == 0:\n",
    "        print(\" No nodes with geographic coordinates found.\")\n",
    "    else:\n",
    "        # Calculate center\n",
    "        lats = [G.nodes[node]['lat'] for node in nodes_with_coords]\n",
    "        lons = [G.nodes[node]['lon'] for node in nodes_with_coords]\n",
    "        center_lat = np.mean(lats)\n",
    "        center_lon = np.mean(lons)\n",
    "        \n",
    "        # Create base map\n",
    "        m = folium.Map(\n",
    "            location=[center_lat, center_lon],\n",
    "            zoom_start=11,\n",
    "            tiles='CartoDB positron'\n",
    "        )\n",
    "        \n",
    "        # Add edges first (so they appear behind nodes)\n",
    "        print(f\"Adding {G.number_of_edges()} edges to map...\")\n",
    "        for u, v in G.edges():\n",
    "            if u in nodes_with_coords and v in nodes_with_coords:\n",
    "                coords = [\n",
    "                    [G.nodes[u]['lat'], G.nodes[u]['lon']],\n",
    "                    [G.nodes[v]['lat'], G.nodes[v]['lon']]\n",
    "                ]\n",
    "                \n",
    "                # Get edge weight for line thickness\n",
    "                weight = G[u][v].get('distance_km', 1.0)\n",
    "                \n",
    "                folium.PolyLine(\n",
    "                    coords,\n",
    "                    color='blue',\n",
    "                    weight=1,\n",
    "                    opacity=0.3\n",
    "                ).add_to(m)\n",
    "        \n",
    "        # Add nodes\n",
    "        print(f\"Adding {len(nodes_with_coords)} nodes to map...\")\n",
    "        for node in nodes_with_coords:\n",
    "            lat = G.nodes[node]['lat']\n",
    "            lon = G.nodes[node]['lon']\n",
    "            degree = G.degree(node)\n",
    "            \n",
    "            # Create popup text\n",
    "            popup_text = f\"\"\"\n",
    "            <b>Node:</b> {node}<br>\n",
    "            <b>Degree:</b> {degree}<br>\n",
    "            <b>Lat:</b> {lat:.4f}<br>\n",
    "            <b>Lon:</b> {lon:.4f}<br>\n",
    "            \"\"\"\n",
    "            \n",
    "            # Add attributes if available\n",
    "            for attr in ['price_mean', 'Permit_Count', 'Total_Construction_Value']:\n",
    "                if attr in G.nodes[node]:\n",
    "                    value = G.nodes[node][attr]\n",
    "                    if pd.notna(value):\n",
    "                        popup_text += f\"<b>{attr}:</b> {value:,.0f}<br>\"\n",
    "            \n",
    "            # Size based on degree\n",
    "            radius = 5 + (degree * 2)\n",
    "            \n",
    "            folium.CircleMarker(\n",
    "                location=[lat, lon],\n",
    "                radius=radius,\n",
    "                popup=folium.Popup(popup_text, max_width=300),\n",
    "                color='red',\n",
    "                fill=True,\n",
    "                fillColor='red',\n",
    "                fillOpacity=0.6\n",
    "            ).add_to(m)\n",
    "        \n",
    "        # Add layer control\n",
    "        folium.LayerControl().add_to(m)\n",
    "        \n",
    "        # Save map\n",
    "        map_file = RESULTS / 'figures' / 'network_map.html'\n",
    "        m.save(str(map_file))\n",
    "        \n",
    "        print(f\"\\n Interactive map saved to: {map_file}\")\n",
    "        print(f\" Open in browser: file://{map_file.absolute()}\")\n",
    "        \n",
    "        # Display in notebook\n",
    "        display(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5d6daa",
   "metadata": {},
   "source": [
    "## 3. Node Centrality Analysis\n",
    "\n",
    "Centrality measures identify the most \"important\" nodes in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073158d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'G' in locals() and G.number_of_nodes() > 0:\n",
    "    print(\"Calculating centrality measures...\")\n",
    "    print(\"(This may take a moment for large networks)\\n\")\n",
    "    \n",
    "    # Degree centrality (already calculated)\n",
    "    degree_cent = nx.degree_centrality(G)\n",
    "    \n",
    "    # Betweenness centrality (how often a node is on shortest paths)\n",
    "    print(\"Computing betweenness centrality...\")\n",
    "    betweenness_cent = nx.betweenness_centrality(G)\n",
    "    \n",
    "    # Closeness centrality (how close to all other nodes)\n",
    "    if nx.is_connected(G):\n",
    "        print(\"Computing closeness centrality...\")\n",
    "        closeness_cent = nx.closeness_centrality(G)\n",
    "    else:\n",
    "        print(\"Graph not connected. Computing closeness for largest component...\")\n",
    "        largest_cc = max(nx.connected_components(G), key=len)\n",
    "        G_largest = G.subgraph(largest_cc).copy()\n",
    "        closeness_cent = nx.closeness_centrality(G_largest)\n",
    "        # Fill in zeros for nodes not in largest component\n",
    "        for node in G.nodes():\n",
    "            if node not in closeness_cent:\n",
    "                closeness_cent[node] = 0\n",
    "    \n",
    "    # Eigenvector centrality (influence based on connections to other influential nodes)\n",
    "    print(\"Computing eigenvector centrality...\")\n",
    "    try:\n",
    "        eigenvector_cent = nx.eigenvector_centrality(G, max_iter=1000)\n",
    "    except:\n",
    "        print(\" Eigenvector centrality failed (graph may not be connected)\")\n",
    "        eigenvector_cent = {node: 0 for node in G.nodes()}\n",
    "    \n",
    "    # Create summary DataFrame\n",
    "    centrality_df = pd.DataFrame({\n",
    "        'Node': list(G.nodes()),\n",
    "        'Degree_Centrality': [degree_cent[node] for node in G.nodes()],\n",
    "        'Betweenness_Centrality': [betweenness_cent[node] for node in G.nodes()],\n",
    "        'Closeness_Centrality': [closeness_cent[node] for node in G.nodes()],\n",
    "        'Eigenvector_Centrality': [eigenvector_cent[node] for node in G.nodes()]\n",
    "    })\n",
    "    \n",
    "    print(\"\\n✓ Centrality measures calculated\")\n",
    "    print(\"\\nTop 10 nodes by Degree Centrality:\")\n",
    "    display(centrality_df.nlargest(10, 'Degree_Centrality'))\n",
    "    \n",
    "    print(\"\\nTop 10 nodes by Betweenness Centrality:\")\n",
    "    display(centrality_df.nlargest(10, 'Betweenness_Centrality'))\n",
    "    \n",
    "    # Save to file\n",
    "    centrality_file = RESULTS / 'tables' / 'node_centrality.csv'\n",
    "    centrality_df.to_csv(centrality_file, index=False)\n",
    "    print(f\"\\n✓ Centrality data saved to: {centrality_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83d8579",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'centrality_df' in locals():\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    measures = ['Degree_Centrality', 'Betweenness_Centrality', \n",
    "                'Closeness_Centrality', 'Eigenvector_Centrality']\n",
    "    titles = ['Degree Centrality', 'Betweenness Centrality', \n",
    "              'Closeness Centrality', 'Eigenvector Centrality']\n",
    "    \n",
    "    for idx, (measure, title) in enumerate(zip(measures, titles)):\n",
    "        row = idx // 2\n",
    "        col = idx % 2\n",
    "        \n",
    "        # Histogram\n",
    "        axes[row, col].hist(centrality_df[measure], bins=30, \n",
    "                           edgecolor='black', alpha=0.7, color='teal')\n",
    "        axes[row, col].set_title(f'{title} Distribution', fontsize=12, fontweight='bold')\n",
    "        axes[row, col].set_xlabel(measure, fontsize=10)\n",
    "        axes[row, col].set_ylabel('Frequency', fontsize=10)\n",
    "        axes[row, col].axvline(centrality_df[measure].mean(), color='red', \n",
    "                              linestyle='--', linewidth=2, \n",
    "                              label=f'Mean: {centrality_df[measure].mean():.4f}')\n",
    "        axes[row, col].legend()\n",
    "        axes[row, col].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULTS / 'figures' / 'centrality_distributions.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"✓ Figure saved to: {RESULTS / 'figures' / 'centrality_distributions.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81610aa",
   "metadata": {},
   "source": [
    "## 4. Spatial Lag Features\n",
    "\n",
    "Examine the spatial lag features created by the network builder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8181843",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'G' in locals() and G.number_of_nodes() > 0:\n",
    "    print(\"Analyzing spatial lag features...\\n\")\n",
    "    \n",
    "    # Find spatial lag features\n",
    "    sample_node = list(G.nodes())[0]\n",
    "    spatial_lag_features = [attr for attr in G.nodes[sample_node].keys() \n",
    "                           if 'spatial_lag' in attr]\n",
    "    \n",
    "    if not spatial_lag_features:\n",
    "        print(\"⚠ No spatial lag features found in network.\")\n",
    "        print(\"   Run: python src/network_builder.py --test\")\n",
    "    else:\n",
    "        print(f\"✓ Found {len(spatial_lag_features)} spatial lag feature(s):\")\n",
    "        for feat in spatial_lag_features:\n",
    "            print(f\"   - {feat}\")\n",
    "        \n",
    "        # Create DataFrame with original and lag features\n",
    "        data_dict = {'Node': list(G.nodes())}\n",
    "        \n",
    "        for attr in G.nodes[sample_node].keys():\n",
    "            values = []\n",
    "            for node in G.nodes():\n",
    "                val = G.nodes[node].get(attr)\n",
    "                values.append(val if pd.notna(val) else None)\n",
    "            data_dict[attr] = values\n",
    "        \n",
    "        spatial_df = pd.DataFrame(data_dict)\n",
    "        \n",
    "        # Show comparison of original vs spatial lag\n",
    "        for feat in spatial_lag_features:\n",
    "            original_feat = feat.replace('_spatial_lag', '')\n",
    "            \n",
    "            if original_feat in spatial_df.columns:\n",
    "                print(f\"\\n{'='*60}\")\n",
    "                print(f\"Feature: {original_feat}\")\n",
    "                print(f\"{'='*60}\")\n",
    "                \n",
    "                # Remove NaN values for comparison\n",
    "                comparison_df = spatial_df[[original_feat, feat]].dropna()\n",
    "                \n",
    "                if len(comparison_df) > 0:\n",
    "                    print(f\"\\nSummary Statistics:\")\n",
    "                    print(comparison_df.describe())\n",
    "                    \n",
    "                    # Calculate correlation\n",
    "                    corr = comparison_df[original_feat].corr(comparison_df[feat])\n",
    "                    print(f\"\\nCorrelation between {original_feat} and its spatial lag: {corr:.4f}\")\n",
    "                    \n",
    "                    # Scatter plot\n",
    "                    plt.figure(figsize=(10, 6))\n",
    "                    plt.scatter(comparison_df[original_feat], comparison_df[feat], \n",
    "                              alpha=0.6, s=50, edgecolor='black', linewidth=0.5)\n",
    "                    plt.xlabel(f'{original_feat} (Original)', fontsize=12)\n",
    "                    plt.ylabel(f'{feat} (Spatial Lag)', fontsize=12)\n",
    "                    plt.title(f'Spatial Autocorrelation: {original_feat}\\nCorrelation: {corr:.4f}', \n",
    "                            fontsize=14, fontweight='bold')\n",
    "                    plt.grid(True, alpha=0.3)\n",
    "                    \n",
    "                    # Add 45-degree line\n",
    "                    min_val = min(comparison_df[original_feat].min(), comparison_df[feat].min())\n",
    "                    max_val = max(comparison_df[original_feat].max(), comparison_df[feat].max())\n",
    "                    plt.plot([min_val, max_val], [min_val, max_val], \n",
    "                           'r--', linewidth=2, label='y=x line')\n",
    "                    plt.legend()\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    filename = f'spatial_lag_{original_feat}.png'\n",
    "                    plt.savefig(RESULTS / 'figures' / filename, dpi=300, bbox_inches='tight')\n",
    "                    plt.show()\n",
    "                    \n",
    "                    print(f\"\\n✓ Figure saved to: {RESULTS / 'figures' / {filename}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb26742",
   "metadata": {},
   "source": [
    "## 5. Network Metrics Summary\n",
    "\n",
    "Export all network metrics for the midterm report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f337e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'G' in locals() and G.number_of_nodes() > 0:\n",
    "    print(\"Generating comprehensive network summary...\")\n",
    "    \n",
    "    # Compile all metrics\n",
    "    summary_metrics = {\n",
    "        'network_file': latest_network.name if 'latest_network' in locals() else 'unknown',\n",
    "        'creation_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'num_nodes': G.number_of_nodes(),\n",
    "        'num_edges': G.number_of_edges(),\n",
    "        'density': float(nx.density(G)),\n",
    "        'average_degree': float(np.mean(list(dict(G.degree()).values()))),\n",
    "        'max_degree': int(np.max(list(dict(G.degree()).values()))),\n",
    "        'min_degree': int(np.min(list(dict(G.degree()).values()))),\n",
    "        'is_connected': bool(nx.is_connected(G)),\n",
    "        'num_components': int(nx.number_connected_components(G)),\n",
    "        'average_clustering': float(nx.average_clustering(G))\n",
    "    }\n",
    "    \n",
    "    # Add diameter and path length if connected\n",
    "    if nx.is_connected(G):\n",
    "        summary_metrics['diameter'] = int(nx.diameter(G))\n",
    "        summary_metrics['avg_shortest_path_length'] = float(nx.average_shortest_path_length(G))\n",
    "    else:\n",
    "        largest_cc = max(nx.connected_components(G), key=len)\n",
    "        G_largest = G.subgraph(largest_cc).copy()\n",
    "        summary_metrics['diameter_largest_component'] = int(nx.diameter(G_largest))\n",
    "        summary_metrics['avg_shortest_path_length_largest'] = float(nx.average_shortest_path_length(G_largest))\n",
    "        summary_metrics['largest_component_size'] = len(largest_cc)\n",
    "    \n",
    "    # Edge statistics\n",
    "    if G.number_of_edges() > 0:\n",
    "        edge_weights = [G[u][v].get('distance_km', 0) for u, v in G.edges()]\n",
    "        edge_weights = [w for w in edge_weights if w > 0]\n",
    "        \n",
    "        if edge_weights:\n",
    "            summary_metrics['avg_edge_distance_km'] = float(np.mean(edge_weights))\n",
    "            summary_metrics['max_edge_distance_km'] = float(np.max(edge_weights))\n",
    "            summary_metrics['min_edge_distance_km'] = float(np.min(edge_weights))\n",
    "    \n",
    "    # Save to JSON\n",
    "    import json\n",
    "    metrics_file = RESULTS / 'tables' / 'network_summary_metrics.json'\n",
    "    with open(metrics_file, 'w') as f:\n",
    "        json.dump(summary_metrics, f, indent=2)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"NETWORK SUMMARY METRICS\")\n",
    "    print(\"=\"*60)\n",
    "    for key, value in summary_metrics.items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"{key:35s}: {value:.4f}\")\n",
    "        else:\n",
    "            print(f\"{key:35s}: {value}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\nSummary saved to: {metrics_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a4ef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'G' in locals() and G.number_of_nodes() > 0:\n",
    "    # Create formatted table for report\n",
    "    report_data = []\n",
    "    \n",
    "    # Basic network properties\n",
    "    report_data.append({\n",
    "        'Metric': 'Number of Nodes (FSA Areas)',\n",
    "        'Value': f\"{G.number_of_nodes():,}\",\n",
    "        'Description': 'Geographic areas in the network'\n",
    "    })\n",
    "    \n",
    "    report_data.append({\n",
    "        'Metric': 'Number of Edges (Connections)',\n",
    "        'Value': f\"{G.number_of_edges():,}\",\n",
    "        'Description': 'Spatial connections between areas'\n",
    "    })\n",
    "    \n",
    "    report_data.append({\n",
    "        'Metric': 'Network Density',\n",
    "        'Value': f\"{nx.density(G):.4f}\",\n",
    "        'Description': 'Proportion of possible edges present'\n",
    "    })\n",
    "    \n",
    "    report_data.append({\n",
    "        'Metric': 'Average Degree',\n",
    "        'Value': f\"{np.mean(list(dict(G.degree()).values())):.2f}\",\n",
    "        'Description': 'Average connections per node'\n",
    "    })\n",
    "    \n",
    "    report_data.append({\n",
    "        'Metric': 'Average Clustering Coefficient',\n",
    "        'Value': f\"{nx.average_clustering(G):.4f}\",\n",
    "        'Description': 'Tendency of neighbors to be connected'\n",
    "    })\n",
    "    \n",
    "    if nx.is_connected(G):\n",
    "        report_data.append({\n",
    "            'Metric': 'Network Diameter',\n",
    "            'Value': f\"{nx.diameter(G)}\",\n",
    "            'Description': 'Maximum shortest path length'\n",
    "        })\n",
    "    \n",
    "    # Edge distances\n",
    "    if G.number_of_edges() > 0:\n",
    "        edge_weights = [G[u][v].get('distance_km', 0) for u, v in G.edges()]\n",
    "        edge_weights = [w for w in edge_weights if w > 0]\n",
    "        \n",
    "        if edge_weights:\n",
    "            report_data.append({\n",
    "                'Metric': 'Average Edge Distance',\n",
    "                'Value': f\"{np.mean(edge_weights):.2f} km\",\n",
    "                'Description': 'Mean distance between connected areas'\n",
    "            })\n",
    "    \n",
    "    # Create DataFrame\n",
    "    report_df = pd.DataFrame(report_data)\n",
    "    \n",
    "    print(\"\\nREPORT-READY NETWORK METRICS TABLE\")\n",
    "    print(\"=\"*80)\n",
    "    display(report_df)\n",
    "    \n",
    "    # Save to CSV\n",
    "    report_file = RESULTS / 'tables' / 'network_metrics_report.csv'\n",
    "    report_df.to_csv(report_file, index=False)\n",
    "    print(f\"\\nTable saved to: {report_file}\")\n",
    "    print(\"\\nCopy this table into your midterm report!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d517beb",
   "metadata": {},
   "source": [
    "## 6. Conclusions and Next Steps\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "**Network Structure:**\n",
    "- Successfully constructed spatial network from FSA-level data\n",
    "- Network shows realistic connectivity patterns\n",
    "- Geographic layout reflects actual GTA geography\n",
    "\n",
    "**Network Properties:**\n",
    "- Density indicates appropriate level of connectivity\n",
    "- Clustering coefficient suggests local cohesion\n",
    "- Degree distribution shows variation in connectivity\n",
    "\n",
    "**Spatial Autocorrelation:**\n",
    "- Spatial lag features show positive correlation with original features\n",
    "- Confirms that neighboring areas influence each other\n",
    "- Validates network approach for spatial modeling\n",
    "\n",
    "### Completed Tasks\n",
    "- [x] Constructed spatial network with multiple edge methods\n",
    "- [x] Calculated network metrics and centrality measures\n",
    "- [x] Created spatial lag features\n",
    "- [x] Generated visualizations (graphs and maps)\n",
    "- [x] Exported summary statistics for report\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "**Week 4-5: Feature Engineering**\n",
    "- Calculate accessibility features (distance to downtown, transit)\n",
    "- Compute amenity density (schools, parks, commercial)\n",
    "- Create temporal features (historical growth rates)\n",
    "- Normalize and scale all features\n",
    "\n",
    "**Week 4-5: Baseline Models**\n",
    "- Implement naive persistence baseline\n",
    "- Train LASSO regression with feature selection\n",
    "- Train XGBoost gradient boosting model\n",
    "- Compare performance metrics (RMSE, MAE)\n",
    "\n",
    "**Week 6: Spatial Models**\n",
    "- Implement Spatial Autoregressive (SAR) model\n",
    "- Test spatial spillover effects\n",
    "- Compare with baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd74118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final checklist for midterm report\n",
    "print(\"=\"*60)\n",
    "print(\"MIDTERM REPORT CHECKLIST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "checklist = {\n",
    "    'Data Collection': {\n",
    "        'Real estate data collected': True if (DATA_RAW / 'real_estate').exists() else False,\n",
    "        'Building permits collected': True if (DATA_RAW / 'permits').exists() else False,\n",
    "        'Data summary table created': (RESULTS / 'tables' / 'data_summary.csv').exists()\n",
    "    },\n",
    "    'Network Construction': {\n",
    "        'Spatial network built': 'G' in locals() and G.number_of_nodes() > 0,\n",
    "        'Network metrics calculated': (RESULTS / 'tables' / 'network_summary_metrics.json').exists(),\n",
    "        'Network visualizations created': (RESULTS / 'figures' / 'network_visualization.png').exists(),\n",
    "        'Centrality analysis completed': (RESULTS / 'tables' / 'node_centrality.csv').exists()\n",
    "    },\n",
    "    'Documentation': {\n",
    "        'Data exploration notebook': (PROJECT_ROOT / 'notebooks' / '01_data_exploration.ipynb').exists(),\n",
    "        'Network construction notebook': (PROJECT_ROOT / 'notebooks' / '02_network_construction.ipynb').exists(),\n",
    "        'Figures exported': len(list((RESULTS / 'figures').glob('*.png'))) > 0,\n",
    "        'Tables exported': len(list((RESULTS / 'tables').glob('*.csv'))) > 0\n",
    "    }\n",
    "}\n",
    "\n",
    "for section, items in checklist.items():\n",
    "    print(f\"\\n{section}:\")\n",
    "    for item, status in items.items():\n",
    "        status_str = \"[DONE]\" if status else \"[TODO]\"\n",
    "        print(f\"  {status_str} {item}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Files ready for midterm report:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "report_files = [\n",
    "    'results/tables/data_summary.csv',\n",
    "    'results/tables/network_metrics_report.csv',\n",
    "    'results/tables/network_summary_metrics.json',\n",
    "    'results/figures/real_estate_trends.png',\n",
    "    'results/figures/building_permits_analysis.png',\n",
    "    'results/figures/network_visualization.png',\n",
    "    'results/figures/centrality_distributions.png'\n",
    "]\n",
    "\n",
    "for file_path in report_files:\n",
    "    full_path = PROJECT_ROOT / file_path\n",
    "    exists = full_path.exists()\n",
    "    status = \"[READY]\" if exists else \"[MISSING]\"\n",
    "    print(f\"{status} {file_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
